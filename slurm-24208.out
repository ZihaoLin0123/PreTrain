/var/spool/slurmd/job24208/slurm_script: line 12: activate: No such file or directory
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
Overriding config with config/train_gpt2.py:
# config for training GPT-2 (124M) down to very nice loss of ~2.85 on 1 node of 8X A100 40GB
# launch as the following (e.g. in a screen session) and wait ~5 days:
# $ torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py

wandb_log = True
wandb_project = 'owt'
wandb_run_name='gpt2-124M'

# these make the total batch size be ~0.5M
# 12 batch size * 1024 block size * 5 gradaccum * 8 GPUs = 491,520
batch_size =20
block_size = 1024
gradient_accumulation_steps = 3

# this makes total number of tokens be 300B
max_iters = 600000
lr_decay_iters = 600000

# eval stuff
eval_interval = 1000
eval_iters = 200
log_interval = 10

# weight decay
weight_decay = 1e-1

Initializing a new model from scratch
defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)
number of parameters: 123.59M
using fused AdamW: True
wandb: Currently logged in as: zihaolin. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/pengyue/.netrc
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/pengyue/PreTrain/wandb/run-20230330_164447-x2sto8eu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gpt2-124M
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zihaolin/owt
wandb: üöÄ View run at https://wandb.ai/zihaolin/owt/runs/x2sto8eu
slurmstepd-hgx049: error: *** JOB 24208 ON hgx049 CANCELLED AT 2023-03-30T16:46:03 ***
