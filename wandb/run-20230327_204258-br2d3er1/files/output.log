step 0: train loss 10.9886, val loss 10.9898
iter 0: loss 10.9932, time 27490.51ms, mfu -100.00%
iter 10: loss 10.3931, time 775.37ms, mfu 21.71%
iter 20: loss 9.7772, time 775.02ms, mfu 21.71%
iter 30: loss 9.5051, time 775.99ms, mfu 21.71%
iter 40: loss 9.2092, time 775.95ms, mfu 21.71%
iter 50: loss 8.9870, time 775.50ms, mfu 21.71%
iter 60: loss 8.8507, time 775.08ms, mfu 21.71%
iter 70: loss 8.5594, time 775.60ms, mfu 21.71%
iter 80: loss 8.4283, time 775.58ms, mfu 21.71%
iter 90: loss 8.2031, time 775.33ms, mfu 21.71%
iter 100: loss 8.0554, time 776.97ms, mfu 21.70%
iter 110: loss 8.0444, time 774.89ms, mfu 21.70%
iter 120: loss 7.6459, time 774.43ms, mfu 21.71%
iter 130: loss 7.4058, time 775.44ms, mfu 21.71%
iter 140: loss 7.4588, time 775.01ms, mfu 21.71%
iter 150: loss 7.0739, time 775.18ms, mfu 21.71%
iter 160: loss 6.9751, time 775.64ms, mfu 21.71%
iter 170: loss 7.0007, time 774.96ms, mfu 21.71%
iter 180: loss 6.9654, time 775.48ms, mfu 21.71%
iter 190: loss 6.8672, time 775.76ms, mfu 21.71%
iter 200: loss 6.6787, time 774.96ms, mfu 21.71%
iter 210: loss 6.8240, time 775.16ms, mfu 21.71%
iter 220: loss 6.4072, time 774.93ms, mfu 21.71%
iter 230: loss 6.4966, time 775.68ms, mfu 21.71%
iter 240: loss 6.2581, time 776.03ms, mfu 21.71%
iter 250: loss 6.5370, time 775.19ms, mfu 21.71%
iter 260: loss 6.5452, time 775.19ms, mfu 21.71%
iter 270: loss 6.4623, time 775.72ms, mfu 21.71%
iter 280: loss 6.3373, time 776.24ms, mfu 21.71%
iter 290: loss 6.2603, time 776.32ms, mfu 21.70%
iter 300: loss 6.2881, time 775.36ms, mfu 21.70%
iter 310: loss 6.4159, time 775.80ms, mfu 21.70%
iter 320: loss 6.4692, time 775.44ms, mfu 21.70%
iter 330: loss 6.3894, time 775.85ms, mfu 21.70%
iter 340: loss 6.2005, time 775.57ms, mfu 21.70%
iter 350: loss 6.3761, time 775.72ms, mfu 21.70%
iter 360: loss 6.2587, time 775.06ms, mfu 21.70%
iter 370: loss 6.1712, time 775.06ms, mfu 21.71%
iter 380: loss 6.1566, time 775.70ms, mfu 21.70%
iter 390: loss 5.9115, time 777.34ms, mfu 21.70%
iter 400: loss 6.0872, time 775.04ms, mfu 21.70%
iter 410: loss 6.1063, time 775.49ms, mfu 21.70%
iter 420: loss 5.8982, time 775.90ms, mfu 21.70%
iter 430: loss 6.3102, time 775.32ms, mfu 21.70%
iter 440: loss 5.9314, time 776.22ms, mfu 21.70%
iter 450: loss 5.8322, time 776.24ms, mfu 21.70%
iter 460: loss 6.1216, time 775.56ms, mfu 21.70%
iter 470: loss 5.7520, time 777.06ms, mfu 21.70%
iter 480: loss 5.8976, time 775.80ms, mfu 21.70%
iter 490: loss 5.8180, time 774.93ms, mfu 21.70%
iter 500: loss 5.6636, time 774.97ms, mfu 21.70%
Traceback (most recent call last):
  File "/home/linzihao/PreTrain/PreTrain/train.py", line 293, in <module>
    scaler.scale(loss).backward()
  File "/home/linzihao/anaconda3/envs/transformer/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/linzihao/anaconda3/envs/transformer/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt