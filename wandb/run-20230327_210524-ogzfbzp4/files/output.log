step 0: train loss 10.9886, val loss 10.9898
iter 0: loss 10.9932, time 24657.51ms, mfu -100.00%
iter 10: loss 10.3931, time 776.17ms, mfu 21.69%
iter 20: loss 9.7772, time 775.63ms, mfu 21.69%
iter 30: loss 9.5051, time 775.46ms, mfu 21.69%
iter 40: loss 9.2092, time 775.88ms, mfu 21.69%
iter 50: loss 8.9870, time 775.53ms, mfu 21.69%
iter 60: loss 8.8507, time 776.52ms, mfu 21.69%
iter 70: loss 8.5594, time 776.40ms, mfu 21.69%
iter 80: loss 8.4283, time 782.43ms, mfu 21.67%
iter 90: loss 8.2031, time 775.69ms, mfu 21.67%
iter 100: loss 8.0554, time 775.95ms, mfu 21.68%
iter 110: loss 8.0444, time 775.95ms, mfu 21.68%
iter 120: loss 7.6459, time 779.99ms, mfu 21.67%
iter 130: loss 7.4058, time 776.27ms, mfu 21.67%
iter 140: loss 7.4588, time 776.40ms, mfu 21.67%
iter 150: loss 7.0739, time 776.04ms, mfu 21.67%
iter 160: loss 6.9751, time 776.60ms, mfu 21.67%
iter 170: loss 7.0007, time 775.93ms, mfu 21.67%
iter 180: loss 6.9654, time 776.01ms, mfu 21.68%
iter 190: loss 6.8672, time 775.95ms, mfu 21.68%
iter 200: loss 6.6787, time 776.16ms, mfu 21.68%
iter 210: loss 6.8240, time 776.12ms, mfu 21.68%
iter 220: loss 6.4072, time 775.44ms, mfu 21.68%
iter 230: loss 6.4966, time 775.54ms, mfu 21.68%
iter 240: loss 6.2581, time 776.10ms, mfu 21.69%
iter 250: loss 6.5370, time 776.27ms, mfu 21.68%
iter 260: loss 6.5452, time 776.67ms, mfu 21.68%
iter 270: loss 6.4623, time 775.98ms, mfu 21.68%
iter 280: loss 6.3373, time 776.10ms, mfu 21.68%
iter 290: loss 6.2603, time 775.64ms, mfu 21.69%
iter 300: loss 6.2881, time 786.79ms, mfu 21.66%
iter 310: loss 6.4159, time 775.59ms, mfu 21.66%
iter 320: loss 6.4692, time 776.37ms, mfu 21.66%
iter 330: loss 6.3894, time 775.75ms, mfu 21.67%
iter 340: loss 6.2005, time 776.52ms, mfu 21.67%
iter 350: loss 6.3761, time 776.15ms, mfu 21.67%
iter 360: loss 6.2587, time 775.54ms, mfu 21.67%
iter 370: loss 6.1712, time 776.36ms, mfu 21.67%
iter 380: loss 6.1566, time 776.01ms, mfu 21.68%
iter 390: loss 5.9115, time 776.41ms, mfu 21.68%
iter 400: loss 6.0872, time 775.64ms, mfu 21.68%
iter 410: loss 6.1063, time 778.01ms, mfu 21.67%
iter 420: loss 5.8982, time 775.62ms, mfu 21.68%
iter 430: loss 6.3102, time 776.20ms, mfu 21.68%
iter 440: loss 5.9314, time 776.15ms, mfu 21.68%
iter 450: loss 5.8322, time 776.37ms, mfu 21.68%
iter 460: loss 6.1216, time 775.61ms, mfu 21.68%
iter 470: loss 5.7520, time 856.76ms, mfu 21.48%
iter 480: loss 5.8976, time 775.90ms, mfu 21.50%
iter 490: loss 5.8180, time 776.26ms, mfu 21.52%
iter 500: loss 5.6636, time 775.72ms, mfu 21.54%
iter 510: loss 5.8885, time 776.03ms, mfu 21.55%
iter 520: loss 5.4678, time 776.19ms, mfu 21.56%
iter 530: loss 5.8130, time 775.19ms, mfu 21.58%
iter 540: loss 5.6437, time 775.37ms, mfu 21.59%
iter 550: loss 5.7045, time 776.06ms, mfu 21.60%
iter 560: loss 5.5485, time 776.91ms, mfu 21.61%
iter 570: loss 5.4652, time 776.10ms, mfu 21.62%
iter 580: loss 5.5640, time 775.98ms, mfu 21.62%
iter 590: loss 5.5697, time 776.24ms, mfu 21.63%
iter 600: loss 5.6342, time 780.08ms, mfu 21.63%
iter 610: loss 5.7865, time 776.08ms, mfu 21.63%
iter 620: loss 5.7839, time 776.86ms, mfu 21.64%
iter 630: loss 5.5169, time 776.46ms, mfu 21.64%
iter 640: loss 5.2508, time 776.20ms, mfu 21.64%
iter 650: loss 5.5833, time 775.61ms, mfu 21.65%
iter 660: loss 5.4791, time 775.60ms, mfu 21.66%
iter 670: loss 5.6827, time 776.39ms, mfu 21.66%
iter 680: loss 5.5161, time 775.77ms, mfu 21.66%
Traceback (most recent call last):
  File "/home/linzihao/PreTrain/PreTrain/train.py", line 298, in <module>
    scaler.scale(loss).backward()
  File "/home/linzihao/anaconda3/envs/transformer/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/linzihao/anaconda3/envs/transformer/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt